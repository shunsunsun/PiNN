{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customizing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data list dataset\n",
    "\n",
    "Suppose your dataset can be represented as a list and each data point can \n",
    "be accessed separately with some function.\n",
    "\n",
    "The list dataset descriptor helps you to transform your reader function to \n",
    "a dataset loader, with handy options to split your dataset.\n",
    "The list can be your list of filenames of structures, or identifiers to \n",
    "retrieve your data points, e.g. ID from some online database.\n",
    "\n",
    "The advantage of this approach is that you only need to write the reader for \n",
    "one data point, \n",
    "and you can get the tensorflow dataset objects with reasonably optimized IO.\n",
    "Later, it's also easy to convert your dataset into the TFRecord format \n",
    "if you need to train on the cloud or further improve the performance.\n",
    "\n",
    "We'll demonstrate with a list of ASE atoms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase import Atoms\n",
    "datalist = [Atoms(elem) for elem in ['Cu', 'Ag', 'Au']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of training ANN potentials, you typically need to provide the \n",
    "elements, coordinates and potential energy of a struture. \n",
    "\n",
    "Your reader function should take one list element as input, \n",
    "and return a dictionary consisting of:\n",
    "\n",
    "- `'atoms'`: the elements of shape [n_atoms]\n",
    "- `'coord'`: the coordinates of shape [n_atoms, 3]\n",
    "- `'e_data'`: a single number\n",
    "\n",
    "After you have got your reader function, decorate it with the `list_loader`\n",
    "decorator to transform it into a dataset loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinn.io import list_loader\n",
    "\n",
    "@list_loader()\n",
    "def load_ase_list(atoms):\n",
    "    import numpy as np\n",
    "    datum = {'elems': atoms.numbers,\n",
    "            'coord': atoms.positions,\n",
    "            'e_data': 0.0}\n",
    "    return datum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it, you've got your customized dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yunqi/miniconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "{'elems': array([29], dtype=int32), 'coord': array([[0., 0., 0.]], dtype=float32), 'e_data': 0.0}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "dataset = load_ase_list(datalist)['train']\n",
    "d = dataset.make_one_shot_iterator().get_next()\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Force and cell\n",
    "\n",
    "By default, the list loader expects the loader to return the elements, coordinates and \n",
    "total energy of each structure. It is also usual to have nuclei forces and pbc in the training data.\n",
    "\n",
    "The default behavior of list_loader can be changed with the `pbc` and `force` options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'elems': array([29], dtype=int32), 'coord': array([[0., 0., 0.]], dtype=float32), 'e_data': 0.0, 'cell': array([[0., 0., 0.],\n",
      "       [0., 0., 0.],\n",
      "       [0., 0., 0.]], dtype=float32), 'f_data': array([[0., 0., 0.]], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "@list_loader(pbc=True, force=True)\n",
    "def load_ase_list(atoms):\n",
    "    import numpy as np\n",
    "    data = {'elems': atoms.numbers,\n",
    "            'coord': atoms.positions,\n",
    "            'cell': atoms.cell,\n",
    "            'f_data': np.zeros_like(atoms.positions),\n",
    "            'e_data': 0.0}\n",
    "    return data\n",
    "\n",
    "dataset = load_ase_list(datalist)['train']\n",
    "d = dataset.make_one_shot_iterator().get_next()\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format dict\n",
    "\n",
    "For even more complex dataset structures, you can instead supply a format_dict\n",
    "to build your list loader.\n",
    "Note that in the current version, the dataset is always expected to be \n",
    "a dictionary of tensors.\n",
    "\n",
    "For example, we add a molecular weight entry to the dataset here.\n",
    "The format dict should provide the shape and datatype of each \n",
    "entry. \n",
    "In the case that a certain dimension is unknow, e.g. the number of atoms,\n",
    "use `None` as the dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_dict = {\n",
    "    'elems': {'dtype':  tf.int32,   'shape': [None]},\n",
    "    'coord': {'dtype':  tf.float32, 'shape': [None, 3]},\n",
    "    'e_data': {'dtype': tf.float32, 'shape': []},\n",
    "    'mw_data': {'dtype': tf.float32, 'shape': []}}\n",
    "\n",
    "@list_loader(format_dict=format_dict)\n",
    "def load_ase_list(atoms):\n",
    "    data = {'elems': atoms.numbers,\n",
    "            'coord': atoms.positions,\n",
    "            'e_data': 0.0,\n",
    "            'mw_data': atoms.get_masses().sum()}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'elems': array([29], dtype=int32), 'coord': array([[0., 0., 0.]], dtype=float32), 'e_data': 0.0, 'mw_data': 63.546}\n"
     ]
    }
   ],
   "source": [
    "dataset = load_ase_list(datalist)['train']\n",
    "d = dataset.make_one_shot_iterator().get_next()\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading trajectories\n",
    "\n",
    "It's rather common to have trajectories as training data. \n",
    "However, trajectories are harder to handle compared to lists as \n",
    "it's not trivial how many data points there are and how they should be split.\n",
    "\n",
    "One solution is to load all the data into the memory once.\n",
    "A more sophisticated solution is to quickly scan through the dataset and \n",
    "get a list of \"positions\" which can be used to read a particular frame.\n",
    "\n",
    "You might want to look into `pinn.io.runner` or `pinn.io.cp2k`\n",
    "if you would like to implement something like that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
