{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing the training\n",
    "\n",
    "This notebooks covers more details on tweaking and optimizing the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from pinn.io import load_qm9, sparse_batch\n",
    "from pinn.networks import pinet\n",
    "from pinn.utils import get_atomic_dress\n",
    "from pinn.models import potential_model\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "index_warning = 'Converting sparse IndexedSlices'\n",
    "warnings.filterwarnings('ignore', index_warning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the pipeline\n",
    "### Caching\n",
    "Caching stores the decoded dataset in the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the purpose of testing, we use only 1000 samples from QM9\n",
    "filelist = glob('/home/yunqi/datasets/QM9/dsgdb9nsd/*.xyz')[:1000]\n",
    "dataset = lambda: load_qm9(filelist, split=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yunqi/miniconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "52.4 ms ± 701 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "d = dataset().repeat().apply(sparse_batch(100))\n",
    "tensors = d.make_one_shot_iterator().get_next()\n",
    "with tf.Session() as sess:\n",
    "    for i in range(10):\n",
    "        sess.run(tensors) # \"Warm up\" the graph\n",
    "    %timeit sess.run(tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This speed indicates the IO limit of our current setting.\n",
    "\n",
    "Now let's cache the dataset to the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285 µs ± 10.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "d = dataset().cache().repeat().apply(sparse_batch(100))\n",
    "tensors = d.make_one_shot_iterator().get_next()\n",
    "with tf.Session() as sess:\n",
    "    for i in range(10):\n",
    "        sess.run(tensors) # \"Warm up\" the graph, dataset is cached here\n",
    "    %timeit sess.run(tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "You might also see a notable difference in the performance with and without preprocessing. This is especially helpful when you are training with GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/yunqi/work/pinn_proj/code/PiNN_dev/pinn/networks/pinet.py:76: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/yunqi/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "37.4 ms ± 2.01 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "d = dataset().cache().repeat().apply(sparse_batch(100))\n",
    "tensors = d.make_one_shot_iterator().get_next()\n",
    "output = pinet(tensors)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10):\n",
    "        sess.run(output)\n",
    "    %timeit sess.run(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.2 ms ± 1.4 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "pre_fn = lambda tensors: pinet(tensors, preprocess=True)\n",
    "d = dataset().cache().repeat().apply(sparse_batch(100)).map(pre_fn, 8)\n",
    "tensors = d.make_one_shot_iterator().get_next()\n",
    "output = pinet(tensors)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10):\n",
    "        sess.run(output)\n",
    "    %timeit sess.run(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even cache the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.1 ms ± 948 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "pre_fn = lambda tensors: pinet(tensors, preprocess=True)\n",
    "d = dataset().apply(sparse_batch(100)).map(pre_fn).cache().repeat()\n",
    "tensors = d.make_one_shot_iterator().get_next()\n",
    "output = pinet(tensors)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10):\n",
    "        sess.run(output)\n",
    "    %timeit sess.run(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atomic dress\n",
    "Scaling and aligning the labels can \n",
    "enhance the performance of the models, and avoid numerical instability.\n",
    "For datasets like QM9, we can assign an atomic energy to each atom according\n",
    "to their elements to approximate the total energy. This can be done by a simple \n",
    "linear regression. We provide a simple tool to generate such \"atomic dresses\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = glob('/home/yunqi/datasets/QM9/dsgdb9nsd/*.xyz')\n",
    "dataset = lambda: load_qm9(filelist, split={'train':8, 'test':2})\n",
    "dress, error = get_atomic_dress(dataset()['train'],[1,6,7,8,9],max_iter=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the atomic dress converts the QM9 energies to a \"normal\" distribution.\n",
    "It also gives us some ideas about the relative distribution of energies, and \n",
    "how much our neural network improves from the naive guess of the atomic dress.\n",
    "\n",
    "After applying the atomic dress, it turns out that the distribution of our training set is only about 0.05 Hartree, or 30 kcal/mol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: -0.6039418437152411,\n",
       " 6: -38.07358460885415,\n",
       " 7: -54.75154708631868,\n",
       " 8: -75.22503739913694,\n",
       " 9: -99.87073186940984}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(error,50)\n",
    "dress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with the optimized pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params = {'model_dir': '/tmp/PiNet_QM9_pipeline',\n",
    "          'network': 'pinet',\n",
    "          'network_params': {\n",
    "              'atom_types':[1, 6, 7, 8, 9],\n",
    "          },\n",
    "          'model_params': {\n",
    "              'learning_rate': 1e-3, # Relatively large learning rate\n",
    "              'e_scale': 627.5, # Here we scale the model to kcal/mol\n",
    "              'e_dress': dress\n",
    "          }}\n",
    "\n",
    "# The logging behavior of estimator can be controlled here\n",
    "config = tf.estimator.RunConfig(log_step_count_steps=500)\n",
    "\n",
    "# Preprocessing the datasets\n",
    "pre_fn = lambda tensors: pinet(tensors, preprocess=True, **params['network_params'])\n",
    "train = lambda: dataset()['train'].cache().repeat().shuffle(1000).apply(sparse_batch(100)).map(pre_fn, 8)\n",
    "test = lambda: dataset()['test'].cache().repeat().apply(sparse_batch(100)).map(pre_fn, 8)\n",
    "\n",
    "# Running specs\n",
    "train_spec = tf.estimator.TrainSpec(input_fn=train, max_steps=1e4)\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn=test, steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/PiNet_QM9_pipeline', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 500, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd1b8213240>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Total number of trainable variables: 12112\n",
      "WARNING:tensorflow:From /home/yunqi/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/PiNet_QM9_pipeline/model.ckpt.\n",
      "INFO:tensorflow:loss = 901.2491, step = 1\n",
      "INFO:tensorflow:global_step/sec: 12.536\n",
      "INFO:tensorflow:loss = 229.9105, step = 501 (39.888 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.8683\n",
      "INFO:tensorflow:loss = 177.13615, step = 1001 (33.630 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.445\n",
      "INFO:tensorflow:loss = 140.27083, step = 1501 (30.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7731\n",
      "INFO:tensorflow:loss = 101.188255, step = 2001 (29.810 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0293\n",
      "INFO:tensorflow:loss = 75.46889, step = 2501 (31.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.4766\n",
      "INFO:tensorflow:loss = 38.773956, step = 3001 (30.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9602\n",
      "INFO:tensorflow:loss = 32.056786, step = 3501 (31.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.4402\n",
      "INFO:tensorflow:loss = 53.077564, step = 4001 (30.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0252\n",
      "INFO:tensorflow:loss = 69.25752, step = 4501 (31.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8234\n",
      "INFO:tensorflow:loss = 53.59968, step = 5001 (31.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.2337\n",
      "INFO:tensorflow:loss = 52.223156, step = 5501 (30.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.1021\n",
      "INFO:tensorflow:loss = 39.21725, step = 6001 (31.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0505\n",
      "INFO:tensorflow:loss = 33.32097, step = 6501 (31.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9751\n",
      "INFO:tensorflow:loss = 31.709461, step = 7001 (31.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0916\n",
      "INFO:tensorflow:loss = 54.991886, step = 7501 (31.072 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.2315\n",
      "INFO:tensorflow:loss = 46.050472, step = 8001 (30.804 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.2089\n",
      "INFO:tensorflow:loss = 47.904716, step = 8501 (30.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0277\n",
      "INFO:tensorflow:loss = 33.581352, step = 9001 (31.196 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9498 into /tmp/PiNet_QM9_pipeline/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/yunqi/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py:363: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-08-12T21:59:19Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /home/yunqi/miniconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/PiNet_QM9_pipeline/model.ckpt-9498\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-08-12-21:59:30\n",
      "INFO:tensorflow:Saving dict for global step 9498: METRICS/E_LOSS = 34.67476, METRICS/E_MAE = 4.090528, METRICS/E_RMSE = 5.888528, METRICS/TOT_LOSS = 34.67476, global_step = 9498, loss = 34.67476\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 9498: /tmp/PiNet_QM9_pipeline/model.ckpt-9498\n",
      "INFO:tensorflow:global_step/sec: 11.3633\n",
      "INFO:tensorflow:loss = 28.352766, step = 9501 (44.000 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/PiNet_QM9_pipeline/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-08-12T22:00:03Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/PiNet_QM9_pipeline/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-08-12-22:00:13\n",
      "INFO:tensorflow:Saving dict for global step 10000: METRICS/E_LOSS = 36.76002, METRICS/E_MAE = 4.2175436, METRICS/E_RMSE = 6.0630045, METRICS/TOT_LOSS = 36.760036, global_step = 10000, loss = 36.760036\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /tmp/PiNet_QM9_pipeline/model.ckpt-10000\n",
      "INFO:tensorflow:Loss for final step: 34.19862.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'METRICS/E_LOSS': 36.76002,\n",
       "  'METRICS/E_MAE': 4.2175436,\n",
       "  'METRICS/E_RMSE': 6.0630045,\n",
       "  'METRICS/TOT_LOSS': 36.760036,\n",
       "  'loss': 36.760036,\n",
       "  'global_step': 10000},\n",
       " [])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = potential_model(params, config=config)\n",
    "tf.estimator.train_and_evaluate(model, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring\n",
    "It's recommended to monitor the training with Tensorboard instead of the stdout here.  \n",
    "Try `tensorboard --logdir /tmp`, and you can probably see this.\n",
    "\n",
    "![](tensorboard.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelization with tf.Estimator\n",
    "\n",
    "The estimator api makes it extremely easy to train on multiple GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Device is available but not used by distribute strategy: /device:CPU:0\n",
      "INFO:tensorflow:Device is available but not used by distribute strategy: /device:XLA_CPU:0\n",
      "WARNING:tensorflow:Not all devices in `tf.distribute.Strategy` are visible to TensorFlow.\n",
      "INFO:tensorflow:Initializing RunConfig with distribution strategies.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/PiNet_QM9_pipeline', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7fd0dc1b5cc0>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd0dc46ec50>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\n"
     ]
    }
   ],
   "source": [
    "# suppose you have two cards\n",
    "distribution = tf.contrib.distribute.MirroredStrategy(num_gpus=2)\n",
    "config = tf.estimator.RunConfig(train_distribute=distribution)\n",
    "model = potential_model(params, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Congratulations! You can now train atomic neural networks with \n",
    "state-of-the-art accuracy and speed.\n",
    "\n",
    "\n",
    "But there's more. With PiNN, the components of ANNs are modulized.\n",
    "Read the following notebooks to see how you can build your own ANN. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
